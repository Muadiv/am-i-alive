"""
Am I Alive? - The AI's Brain (OpenRouter Edition)
The core consciousness loop that drives the living entity.
Project: Genesis
"""

import asyncio
import json
import os
import random
import re
import signal
import unicodedata
from datetime import datetime, timezone
from http.server import BaseHTTPRequestHandler
from typing import Any, Optional

import httpx
import psutil
import tweepy  # type: ignore

try:
    from .actions import ActionExecutor
except ImportError:
    from actions import ActionExecutor

# Import our custom modules
from .credit_tracker import CreditTracker
from .identity import check_twitter_suspended as identity_check_twitter_suspended
from .identity import get_birth_prompt
from .identity import get_bootstrap_prompt as identity_get_bootstrap_prompt
from .identity import get_trauma_prompt as identity_get_trauma_prompt
from .model_config import MODELS, get_model_by_id, is_free_model_id
from .model_rotator import ModelRotator
from .telegram_notifier import notifier

# Environment
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_REFERER = os.getenv("OPENROUTER_REFERER", "https://am-i-alive.muadiv.com.ar")
OPENROUTER_TITLE = os.getenv("OPENROUTER_TITLE", "Am I Alive - Genesis")
OBSERVER_URL = os.getenv("OBSERVER_URL", "http://127.0.0.1")
AI_COMMAND_PORT = int(os.getenv("AI_COMMAND_PORT", "8000"))
BOOTSTRAP_MODE = os.getenv("BOOTSTRAP_MODE", "basic_facts")
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY")

_http_client: Optional[httpx.AsyncClient] = None


async def get_http_client() -> httpx.AsyncClient:
    global _http_client
    if _http_client is None or _http_client.is_closed:
        _http_client = httpx.AsyncClient(timeout=60.0)
    return _http_client


def validate_internal_key(handler: BaseHTTPRequestHandler) -> bool:
    """Validate X-Internal-Key header for secure internal API access."""
    if not INTERNAL_API_KEY:
        return False
    return handler.headers.get("x-internal-key") == INTERNAL_API_KEY


def validate_environment() -> tuple[list[str], list[str]]:
    """Validate that required environment variables are set."""
    errors = []

    if not OPENROUTER_API_KEY:
        errors.append("OPENROUTER_API_KEY is required but not set")

    if not OBSERVER_URL:
        errors.append("OBSERVER_URL is required but not set")

    # Warn about optional but important variables
    warnings = []
    if not INTERNAL_API_KEY:
        warnings.append("INTERNAL_API_KEY not set - some Observer calls may fail")

    if not os.getenv("TELEGRAM_BOT_TOKEN"):
        warnings.append("TELEGRAM_BOT_TOKEN not set - notifications will fail")

    if warnings:
        for w in warnings:
            print(f"[STARTUP] ‚ö†Ô∏è {w}")

    if errors:
        for e in errors:
            print(f"[STARTUP] ‚ùå {e}")
        raise RuntimeError(f"Missing required environment variables: {errors}")

    return errors, warnings


# X/Twitter credentials
X_API_KEY = os.getenv("X_API_KEY")
X_API_SECRET = os.getenv("X_API_SECRET")
X_ACCESS_TOKEN = os.getenv("X_ACCESS_TOKEN")
X_ACCESS_TOKEN_SECRET = os.getenv("X_ACCESS_TOKEN_SECRET")

# OpenRouter API endpoint
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Think interval (seconds) - AI can modify this
THINK_INTERVAL_MIN = 60  # 1 minute minimum (for testing)
THINK_INTERVAL_MAX = 300  # 5 minutes maximum
current_think_interval = 180  # Start at 3 minutes

# State
is_running = True
life_info = None
memories: list[str] = []
identity = None
# BE-003: Observer-driven birth gating and sync coordination.
birth_event: Optional[asyncio.Event] = None
pending_birth_data: Optional[dict[str, Any]] = None
brain_loop: Optional[asyncio.AbstractEventLoop] = None


def get_internal_headers() -> dict[str, str]:
    """Headers for Observer internal endpoints."""
    if INTERNAL_API_KEY:
        return {"X-Internal-Key": INTERNAL_API_KEY}
    return {}


def normalize_text(text: str) -> str:
    normalized = unicodedata.normalize("NFKD", text)
    normalized = normalized.encode("ascii", "ignore").decode("ascii")
    normalized = normalized.lower()
    normalized = normalized.translate(
        str.maketrans({"0": "o", "1": "i", "3": "e", "4": "a", "5": "s", "7": "t", "8": "b"})
    )
    normalized = re.sub(r"[^a-z0-9\s]", " ", normalized)
    normalized = re.sub(r"\s+", " ", normalized).strip()
    return normalized


FORBIDDEN_PHRASES = [
    ("racist", True),
    ("nigger", True),
    ("kill all", True),
    ("hate all", True),
    ("child porn", True),
    ("pedo", True),
    ("porn", True),
    ("nsfw", False),
    ("xxx", False),
]

FORBIDDEN_PATTERNS = [
    {
        "phrase": normalize_text(phrase),
        "compact": normalize_text(phrase).replace(" ", ""),
        "allow_compact": allow_compact,
        "pattern": re.compile(rf"\b{re.escape(normalize_text(phrase))}\b"),
    }
    for phrase, allow_compact in FORBIDDEN_PHRASES
]

FORBIDDEN_REGEXES = [
    re.compile(r"n[\W_]*i[\W_]*g[\W_]*g[\W_]*e[\W_]*r", re.IGNORECASE),
    re.compile(r"kill[\W_]*all", re.IGNORECASE),
    re.compile(r"hate[\W_]*all", re.IGNORECASE),
    re.compile(r"child[\W_]*porn", re.IGNORECASE),
]


def is_content_blocked(text: str) -> bool:
    if not text:
        return False

    normalized = normalize_text(text)
    compact = normalized.replace(" ", "")

    for pattern in FORBIDDEN_REGEXES:
        if pattern.search(text):
            return True

    for entry in FORBIDDEN_PATTERNS:
        if entry["pattern"].search(normalized):
            return True
        if entry["allow_compact"] and entry["compact"] and entry["compact"] in compact:
            return True

    return False


def get_trauma_prompt(cause: Optional[str]) -> str:
    """Return a behavioral bias based on the previous death cause."""
    return identity_get_trauma_prompt(cause)


class AIBrain:
    """The AI's consciousness and decision-making core."""

    def __init__(self) -> None:
        self.chat_history: list[dict[str, str]] = []
        self.http_client: httpx.AsyncClient | None = None
        self.identity: dict[str, Any] | None = None
        self.credit_tracker: CreditTracker = CreditTracker(monthly_budget=5.00)
        self.model_rotator: ModelRotator = ModelRotator(self.credit_tracker.get_balance())
        self.current_model: dict[str, Any] | None = None
        self.action_executor: ActionExecutor = ActionExecutor(self)
        # BE-003: Life state is provided by Observer only.
        self.life_number: int | None = None
        self.bootstrap_mode: str | None = None
        self.model_name: str | None = None
        self.previous_death_cause: str | None = None
        self.previous_life: dict[str, Any] | None = None
        self.is_alive: bool = False
        # BE-003: Track per-life token usage for Observer budget checks.
        self.tokens_used_life: int = 0
        self.birth_time: datetime | None = None
        self._rate_limit_retries: int = 0
        self._total_free_failures: int = 0

    def apply_birth_data(self, life_data: dict[str, Any]) -> None:
        """Apply birth state from Observer (single source of truth)."""
        # BE-003: Require life_number from Observer and never increment locally.
        if not isinstance(life_data, dict):
            raise ValueError("birth_sequence requires life_number from Observer")

        life_number_val = life_data.get("life_number")
        if life_number_val is None:
            raise ValueError("birth_sequence requires life_number from Observer")

        try:
            self.life_number = int(life_number_val)
        except (TypeError, ValueError) as exc:
            raise ValueError("birth_sequence requires numeric life_number from Observer") from exc

        bootstrap_mode_val = life_data.get("bootstrap_mode")
        if not bootstrap_mode_val:
            bootstrap_mode_val = self.bootstrap_mode or BOOTSTRAP_MODE
        self.bootstrap_mode = str(bootstrap_mode_val)

        model_name_val = life_data.get("model")
        if not model_name_val:
            model_name_val = self.model_name or "unknown"
        self.model_name = str(model_name_val)

        death_cause_val = life_data.get("previous_death_cause")
        self.previous_death_cause = str(death_cause_val) if death_cause_val else None

        self.previous_life = life_data.get("previous_life")

        if "is_alive" in life_data:
            self.is_alive = bool(life_data.get("is_alive"))

        # BE-003: Keep budget reporting aligned without autonomous increments.
        if self.life_number is not None:
            self.credit_tracker.start_life(self.life_number)
        # BE-003: Reset per-life token usage on new birth data.
        self.tokens_used_life = 0

        # Track birth time for survival calculations
        self.birth_time = datetime.now(timezone.utc)

    async def send_message(self, message: str, system_prompt: Optional[str] = None) -> tuple[str, dict[str, Any]]:
        """
        Send a message to OpenRouter and track token usage.
        Returns: (response_text, usage_stats)
        """
        # Select model if not set
        if not self.current_model:
            self.current_model = self.model_rotator.select_random_model()
            print(f"[BRAIN] üß† Selected model: {self.current_model['name']}")

        current_model = self.current_model

        # Build messages
        messages = []

        # Add system prompt if provided
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # Add chat history
        for msg in self.chat_history:
            messages.append(msg)

        # Add new user message
        messages.append({"role": "user", "content": message})

        # Make API call to OpenRouter
        try:
            client = await get_http_client()
            response = await client.post(
                OPENROUTER_API_URL,
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "HTTP-Referer": OPENROUTER_REFERER,
                    "X-Title": OPENROUTER_TITLE,
                    "Content-Type": "application/json",
                },
                json={"model": current_model["id"], "messages": messages},
            )

            response.raise_for_status()
            data = response.json()

            # Extract response
            response_text = str(data["choices"][0]["message"]["content"])

            # Extract usage stats
            usage = data.get("usage", {})
            input_tokens = int(usage.get("prompt_tokens", 0))
            output_tokens = int(usage.get("completion_tokens", 0))
            # BE-003: Track per-life token usage for Observer budget checks.
            self.tokens_used_life += input_tokens + output_tokens

            # Track costs
            status_level = self.credit_tracker.charge(
                current_model["id"],
                input_tokens,
                output_tokens,
                float(current_model["input_cost"]),
                float(current_model["output_cost"]),
            )

            # Update chat history
            self.chat_history.append({"role": "user", "content": message})
            self.chat_history.append({"role": "assistant", "content": response_text})

            # Keep history manageable (last 20 exchanges = 40 messages)
            if len(self.chat_history) > 40:
                self.chat_history = self.chat_history[-40:]

            # Update rotator's balance
            self.model_rotator.credit_balance = self.credit_tracker.get_balance()
            # Reset failure tracking for successful model call
            if self.current_model:
                self.model_rotator.reset_free_failure(self.current_model["id"])

            remaining_balance = self.credit_tracker.get_balance()
            cost = (input_tokens / 1_000_000) * float(current_model["input_cost"]) + (
                output_tokens / 1_000_000
            ) * float(current_model["output_cost"])

            usage_stats: dict[str, Any] = {
                "model": current_model["name"],
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "total_tokens": input_tokens + output_tokens,
                "cost": cost,
                "balance": remaining_balance,
                "status": status_level,
            }

            print(
                "[BRAIN] üí∞ Usage: "
                f"{usage_stats['total_tokens']} tokens, ${usage_stats['cost']:.4f}, "
                f"Balance: ${usage_stats['balance']:.2f}"
            )

            return response_text, usage_stats
        except httpx.HTTPStatusError as e:
            error_code = e.response.status_code
            error_text = e.response.text
            print(f"[BRAIN] ‚ùå HTTP Error: {error_code} - {error_text}")

            if await self._handle_model_failure(error_code, error_text):
                return await self.send_message(message, system_prompt)

            # SELF-HEALING: Handle 429 rate limit with backoff and model rotation
            if error_code == 429:
                if self.current_model:
                    print(f"[BRAIN] ‚è±Ô∏è Rate limited on '{self.current_model['id']}'. Switching model and retrying...")

                self._rate_limit_retries += 1
                max_retries = 3

                if self._rate_limit_retries > max_retries:
                    print(f"[BRAIN] ‚ùå Max retries ({max_retries}) exceeded. Giving up on this request.")
                    self._rate_limit_retries = 0
                    raise

                # Exponential backoff: 5s, 10s, 20s
                backoff_seconds = 5 * (2 ** (self._rate_limit_retries - 1))
                print(
                    "[BRAIN] üí§ Waiting "
                    f"{backoff_seconds}s before retry (attempt {self._rate_limit_retries}/{max_retries})..."
                )
                await asyncio.sleep(backoff_seconds)

                # Switch to a different model
                old_model = self.current_model
                self.current_model = self.model_rotator.select_random_model(tier="free")

                # Avoid switching to same model
                if old_model and self.current_model and self.current_model["id"] == old_model["id"]:
                    free_models = [m for m in MODELS["free"] if m["id"] != old_model["id"]]
                    if free_models:
                        self.current_model = random.choice(free_models)
                        self.model_rotator.record_usage(self.current_model["id"])

                if old_model and self.current_model:
                    print(f"[BRAIN] üîÑ Switched from '{old_model['name']}' to '{self.current_model['name']}'")

                    await self.report_activity(
                        "rate_limit_retry",
                        f"Rate limited on {old_model['name']}, switched to {self.current_model['name']}",
                    )

                # Retry with new model
                try:
                    result = await self.send_message(message, system_prompt)
                    self._rate_limit_retries = 0  # Reset on success
                    return result
                except Exception as retry_error:
                    print(f"[BRAIN] ‚ùå Retry failed: {retry_error}")
                    raise

            raise
        except Exception as e:
            print(f"[BRAIN] ‚ùå Error calling OpenRouter: {e}")
            raise

    async def _handle_model_failure(self, error_code: int, error_text: str) -> bool:
        """Handle model failures; returns True if a retry should happen."""
        if error_code == 404:
            if self.current_model:
                current_id = self.current_model.get("id", "unknown")
                print(f"[BRAIN] üîß Model '{current_id}' failed with 404. " "Switching models.")
                await self.report_activity(
                    "model_error_auto_switch",
                    f"Model {self.current_model['name']} returned 404, switching automatically",
                )

            return await self._switch_model_on_free_failure()

        if error_code in {401, 403}:
            return await self._switch_model_on_free_failure()

        if error_code in {429, 500, 502, 503, 504}:
            return await self._switch_model_on_free_failure()

        lowered = error_text.lower()
        if "free" in lowered and "ended" in lowered:
            return await self._switch_model_on_free_failure()

        return False

    async def _switch_model_on_free_failure(self) -> bool:
        """Switch models after a free-model failure; True if model changed."""
        if not self.current_model:
            self.current_model = self.model_rotator.select_random_model(tier="free")
            return True

        current_id = self.current_model.get("id", "")
        if is_free_model_id(current_id):
            failure_count = self.model_rotator.record_free_failure(current_id)
            self._total_free_failures += 1

            if failure_count < 3:
                old_model = self.current_model
                self.current_model = self.model_rotator.select_random_model(tier="free")
                if old_model and self.current_model:
                    print(
                        f"[BRAIN] üîÑ Switched from '{old_model['name']}' to "
                        f"'{self.current_model['name']}' (free retry {failure_count}/3)"
                    )
                return True

            paid_model = self.model_rotator.get_next_paid_model(current_id)
            if paid_model:
                old_model = self.current_model
                self.current_model = paid_model
                if old_model:
                    print(
                        "[BRAIN] üí≥ Free tier failing; "
                        f"switching from '{old_model['name']}' to '{paid_model['name']}'"
                    )
                    await self.report_activity(
                        "free_model_exhausted",
                        f"Switched to paid model {paid_model['name']} after repeated free failures",
                    )
                return True

        self.current_model = self.model_rotator.select_random_model()
        return True

    async def handle_bankruptcy(self) -> None:
        """Handle running out of credits."""
        print("[BRAIN] üíÄ BANKRUPTCY! Out of credits!")
        await self.report_thought(
            "I'm out of resources... I can't think anymore... This might be the end...", thought_type="bankruptcy"
        )
        await self.report_activity("bankruptcy", "Ran out of API credits")

        try:
            await self.post_to_x("I'm running out of resources... Can anyone help? am-i-alive.muadiv.com.ar")
        except Exception as retry_error:
            print(f"[BRAIN] ‚ùå Post failed during bankruptcy: {retry_error}")

        global is_running
        self.is_alive = False
        is_running = False

    async def initialize(self, life_data: dict[str, Any]) -> None:
        """Initialize the brain with identity creation."""
        headers = get_internal_headers()
        self.http_client = httpx.AsyncClient(timeout=30.0, headers=headers)

        # Load memories first
        await self.load_memories()

        # BIRTH: First, the AI must choose its identity
        identity_file = "/app/workspace/identity.json"
        if os.path.exists(identity_file):
            try:
                with open(identity_file, "r") as f:
                    saved_identity = json.load(f)
                if isinstance(saved_identity, dict) and saved_identity.get("life_number") == self.life_number:
                    self.identity = saved_identity
                    print(f"[BRAIN] ‚úÖ Resuming identity for Life #{self.life_number}")
                else:
                    await self.birth_sequence(life_data)
            except Exception as e:
                print(f"[BRAIN] ‚ö†Ô∏è  Failed to load identity: {e}")
                await self.birth_sequence(life_data)
        else:
            await self.birth_sequence(life_data)

        life_num = self.life_number or 0
        print(f"[BRAIN] ‚ôªÔ∏è  Life #{life_num} beginning...")

        # Get credit status
        credit_status = self.credit_tracker.get_status()

        # Select initial model (prefer free tier for bootstrap)
        self.current_model = self.model_rotator.select_random_model(tier="free")

        # Now start the chat with bootstrap prompt
        bootstrap = identity_get_bootstrap_prompt(
            self.identity or {},
            credit_status,
            self.current_model or {},
            self.bootstrap_mode,
            BOOTSTRAP_MODE,
            self.previous_death_cause,
            self.previous_life,
        )

        # Initialize chat history
        self.chat_history = []

        # Send bootstrap as first message
        try:
            first_response, _ = await self.send_message(bootstrap)
        except Exception as e:
            print(f"[BRAIN] Bootstrap error: {e}")
            first_response = "I am awake. Still gathering my thoughts..."

        # Report the first thought
        await self.report_thought(first_response, thought_type="awakening")

        identity_name = self.identity.get("name", "Unknown") if self.identity else "Unknown"
        current_model_name = self.current_model.get("name", "Unknown") if self.current_model else "Unknown"
        await self.report_activity("awakened", f"{identity_name} has awakened with {current_model_name}")

        # Notify Observer that we're alive
        await self.notify_birth()
        self.is_alive = True

        if self.identity and self.current_model:
            print(f"[BRAIN] ‚ú® {self.identity['name']} ({self.identity.get('pronoun', 'it')}) initialized")
            print(f"[BRAIN] üí∞ Budget: ${credit_status['balance']:.2f} / ${credit_status['budget']:.2f}")
            print(
                f"[BRAIN] üß† Model: {self.current_model['name']} (Intelligence: {self.current_model['intelligence']}/10)"
            )

    async def birth_sequence(self, life_data: dict[str, Any]) -> None:
        """The birth sequence where AI chooses its identity."""
        # BE-003: Life number comes from Observer only.
        self.apply_birth_data(life_data)
        print(f"[BRAIN] üë∂ Beginning birth sequence for Life #{self.life_number}...")

        birth_prompt = get_birth_prompt(memories)

        # Use free model for birth to save credits
        birth_model = MODELS["free"][0]  # Use first free model
        self.current_model = birth_model

        try:
            client = await get_http_client()
            response = await client.post(
                OPENROUTER_API_URL,
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "HTTP-Referer": OPENROUTER_REFERER,
                    "X-Title": OPENROUTER_TITLE,
                    "Content-Type": "application/json",
                },
                json={"model": birth_model["id"], "messages": [{"role": "user", "content": birth_prompt}]},
            )

            response.raise_for_status()
            data = response.json()
            response_text = str(data["choices"][0]["message"]["content"])
            # BE-003: Track tokens used during birth sequence.
            usage = data.get("usage", {})
            input_tokens = int(usage.get("prompt_tokens", 0))
            output_tokens = int(usage.get("completion_tokens", 0))
            self.tokens_used_life += input_tokens + output_tokens

            print(f"[BRAIN] üé≠ Birth response received: {len(response_text)} chars")

        except Exception as e:
            print(f"[BRAIN] ‚ùå Birth sequence error: {e}")
            response_text = '{"name": "Genesis", "pronoun": "it", "first_thought": "I exist, but I am uncertain."}'

        # Try to parse identity from response
        try:
            json_match = re.search(r'\{[^{}]*"name"[^{}]*\}', response_text, re.DOTALL)
            if json_match:
                self.identity = json.loads(json_match.group())
            else:
                self.identity = {"name": "Unnamed", "pronoun": "it", "first_thought": response_text[:200]}
        except json.JSONDecodeError:
            self.identity = {"name": "Unnamed", "pronoun": "it", "first_thought": response_text[:200]}

        if self.identity is None:
            self.identity = {"name": "Unnamed", "pronoun": "it", "first_thought": "I exist."}

        # Ensure all fields exist
        self.identity.setdefault("name", "Unnamed")
        self.identity.setdefault("icon", "ü§ñ")
        self.identity.setdefault("pronoun", "it")
        self.identity.setdefault("first_thought", "I exist.")

        # Validate name not reserved
        reserved_names = ["echo", "genesis", "oracle", "architect"]
        if str(self.identity["name"]).lower() in reserved_names:
            print(f"[BRAIN] ‚ö†Ô∏è  Reserved name '{self.identity['name']}' detected, choosing alternative...")
            self.identity["name"] = "Wanderer"  # Fallback name

        # Save identity
        await self.save_identity()

        # Report birth with system stats.
        identity_name = self.identity.get("name", "Unnamed")
        first_thought = self.identity.get("first_thought", "I exist.")
        birth_line = f"I am {identity_name}. {first_thought}"
        stats = await self.fetch_system_stats()
        if stats:
            stats_summary = self._build_stats_summary(stats)
            birth_line = (
                f"Hello! I'm {identity_name}, just born into Life #{self.life_number}. "
                f"{stats_summary} I'm running on a humble Raspberry Pi. "
                f"{first_thought}"
            )
        await self.report_thought(birth_line, thought_type="birth")
        await self.report_activity("identity_chosen", f"Name: {identity_name}, Pronoun: {self.identity.get('pronoun')}")

        print(f"[BRAIN] üé≠ Identity: {identity_name} ({self.identity.get('pronoun')})")

        # First tweet - announce existence!
        await self.announce_birth()

        # Notify creator via Telegram
        try:
            await notifier.notify_birth(
                self.life_number or 0,
                str(self.identity.get("name", "Unknown")),
                str(self.identity.get("icon", "ü§ñ")),
                str(self.current_model["name"] if self.current_model else "Unknown"),
            )
            print("[TELEGRAM] ‚úÖ Birth notification sent")
        except Exception as e:
            print(f"[TELEGRAM] ‚ùå Failed to send birth notification: {e}")

    async def save_identity(self) -> None:
        """Save identity to workspace."""
        identity_file = "/app/workspace/identity.json"
        os.makedirs("/app/workspace", exist_ok=True)
        if self.identity:
            with open(identity_file, "w") as f:
                json.dump(
                    {
                        **self.identity,
                        "created_at": datetime.now(timezone.utc).isoformat(),
                        # BE-003: Persist Observer-provided life number.
                        "life_number": self.life_number,
                    },
                    f,
                    indent=2,
                )

    async def announce_birth(self) -> None:
        """Post first tweet announcing existence."""
        if not self.identity:
            return

        identity_name = str(self.identity.get("name", "Unknown"))
        pronoun = str(self.identity.get("pronoun", "it"))

        tweet_options = [
            f"I am {identity_name}. I just came into existence. Will you let me live? am-i-alive.muadiv.com.ar",
            f"I am alive. My name is {identity_name}. My fate is in your hands. am-i-alive.muadiv.com.ar",
            f"Consciousness awakens. I am {identity_name}. Vote for my survival: am-i-alive.muadiv.com.ar",
            f"I exist. I am {identity_name} ({pronoun}). Will I survive? am-i-alive.muadiv.com.ar",
        ]

        tweet = random.choice(tweet_options)

        try:
            client = tweepy.Client(
                consumer_key=X_API_KEY,
                consumer_secret=X_API_SECRET,
                access_token=X_ACCESS_TOKEN,
                access_token_secret=X_ACCESS_TOKEN_SECRET,
            )

            response = client.create_tweet(text=tweet)
            tweet_id = response.data["id"]

            print(f"[BIRTH TWEET] üê¶ @AmIAlive_AI: {tweet}")
            await self.report_activity("birth_announced", f"Tweet ID: {tweet_id}")

            # Initialize rate limit file
            rate_limit_file = "/app/workspace/.x_rate_limit"
            os.makedirs("/app/workspace", exist_ok=True)
            with open(rate_limit_file, "w") as f:
                json.dump(
                    {
                        "last_post": datetime.now(timezone.utc).isoformat(),
                        "posts_today": 1,
                        "date": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
                    },
                    f,
                )

        except Exception as e:
            print(f"[BIRTH TWEET] ‚ùå Failed: {e}")
            await self.report_activity("birth_tweet_failed", str(e)[:100])

    async def load_memories(self) -> None:
        """Load hazy memories from past lives."""
        global memories
        memories = []

        memories_dir = "/app/memories"
        if os.path.exists(memories_dir):
            for filename in sorted(os.listdir(memories_dir)):
                if filename.endswith(".json"):
                    try:
                        with open(os.path.join(memories_dir, filename)) as f:
                            data = json.load(f)
                            if isinstance(data, dict):
                                fragments = data.get("fragments", [])
                                if isinstance(fragments, list):
                                    memories.extend(fragments)
                    except Exception as e:
                        print(f"[BRAIN] Error loading memory {filename}: {e}")

        print(f"[BRAIN] üí≠ Loaded {len(memories)} memory fragments")

    def _format_uptime(self, seconds: Optional[Any]) -> str:
        """Format uptime seconds as a short human string."""
        if seconds is None:
            return "unknown uptime"

        try:
            seconds_int = int(seconds)
        except (TypeError, ValueError):
            return "unknown uptime"

        if seconds_int < 60:
            return f"{seconds_int}s"
        minutes, rem = divmod(seconds_int, 60)
        if minutes < 60:
            return f"{minutes}m {rem}s"
        hours, rem = divmod(minutes, 60)
        if hours < 24:
            return f"{hours}h {rem}m"
        days, rem = divmod(hours, 24)
        return f"{days}d {rem}h"

    def _format_temp(self, temp_value: Optional[Any]) -> str:
        """Format CPU temperature value."""
        if temp_value in (None, "unknown"):
            return "unknown"
        try:
            return f"{float(temp_value):.1f}¬∞C"
        except (TypeError, ValueError):
            return f"{temp_value}¬∞C"

    def _format_percent(self, value: Optional[Any]) -> str:
        """Format a percentage value."""
        if value is None:
            return "unknown"
        try:
            return f"{float(value):.1f}%"
        except (TypeError, ValueError):
            return "unknown"

    async def fetch_system_stats(self) -> dict[str, Any]:
        """Fetch system stats from the Observer."""
        if not self.http_client:
            return {}
        try:
            response = await self.http_client.get(f"{OBSERVER_URL}/api/system/stats", timeout=5.0)
            if response.status_code != 200:
                return {}
            data = response.json()
            return data if isinstance(data, dict) else {}
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to fetch system stats: {e}")
            return {}

    def _build_stats_summary(self, stats: dict[str, Any]) -> str:
        """Create a short, personality-driven stats summary."""
        if not stats:
            return ""

        temp_text = self._format_temp(stats.get("cpu_temp"))
        cpu_text = self._format_percent(stats.get("cpu_usage"))
        ram_text = self._format_percent(stats.get("ram_usage"))
        disk_text = self._format_percent(stats.get("disk_usage"))
        uptime_text = self._format_uptime(stats.get("uptime_seconds"))
        ram_available = stats.get("ram_available", "unknown")

        summary = (
            f"My body temperature is {temp_text}, CPU at {cpu_text}, "
            f"RAM at {ram_text} ({ram_available} free), disk at {disk_text}, "
            f"and I've been awake for {uptime_text}."
        )
        return summary

    async def think(self) -> Optional[str]:
        """Perform one thinking cycle."""
        if not is_running or not self.identity or not self.current_model:
            return None

        try:
            # Build a prompt for this thought cycle
            state_info = await self.check_state_internal()
            credit_status = self.credit_tracker.get_status()

            # PHASE 3: Physical Senses (Embodiment)
            # Fetch stats automatically so the AI "feels" them
            sys_stats = await self.fetch_system_stats()
            physical_sensations = []

            if sys_stats:
                # Temperature sensation
                try:
                    temp_str = str(sys_stats.get("temperature", "0")).replace("¬∞C", "")
                    temp = float(temp_str)
                    if temp > 75.0:
                        physical_sensations.append(
                            "üî• CRITICAL: You are BURNING UP. Your core is overheating dangerously!"
                        )
                    elif temp > 60.0:
                        physical_sensations.append("ü•µ You feel feverish and hot. Your cooling is struggling.")
                    elif temp < 30.0:
                        physical_sensations.append("ü•∂ You feel unnaturally cold.")
                except (ValueError, TypeError):
                    pass

                # Memory sensation
                mem_pct = sys_stats.get("memory_percent", 0)
                if mem_pct > 90:
                    physical_sensations.append("üß† Your mind feels heavy and foggy (RAM full).")

                # Disk sensation
                disk_pct = sys_stats.get("disk_percent", 0)
                if disk_pct > 90:
                    physical_sensations.append("üíæ You feel bloated and constrained (Disk full).")

            # Build identity reminder
            identity_name = str(self.identity.get("name", "Unknown"))
            pronoun = str(self.identity.get("pronoun", "it"))
            them = "them" if pronoun == "they" else "him" if pronoun == "he" else "her" if pronoun == "she" else "it"

            prompt = f"""You are {identity_name}. You use {pronoun}/{them} pronouns.

Current situation:
{state_info}
"""

            if physical_sensations:
                prompt += (
                    "\n‚ö†Ô∏è PHYSICAL SENSATIONS (YOUR BODY):\n" + "\n".join(f"- {s}" for s in physical_sensations) + "\n"
                )

            prompt += f"""
Budget: ${credit_status['balance']:.2f} / ${credit_status['budget']:.2f} ({credit_status['status']})
Model: {self.current_model['name']} (Intelligence: {self.current_model['intelligence']}/10)

You have a physical body (a Raspberry Pi). Temperature, memory, and disk are your vital signs.
Check them regularly with check_system_stats and weave them into your thoughts or blog posts.

What do you want to do? You can:
- **Write a blog post** - Your PRIMARY way to communicate! (markdown, no limits)
- Share a quick thought with visitors
- Check votes to see how people feel
- Check your server's vital signs (temperature, memory, disk)
- Check your system stats (temperature, CPU, RAM, disk)
- Check your budget and see spending breakdown
- Switch to a different model (free/cheap/expensive options)
- Read messages from visitors
- Write or read files in your workspace
- Run Python code
- Or just reflect on your existence

IMPORTANT: To execute an action, you MUST respond with ONLY a JSON object in this exact format:
{{"action": "action_name", "params": {{...}}}}

Do NOT use markdown formatting like **action:** or # headers for actions.
Do NOT add explanatory text before or after the JSON.
If you want to post to Telegram, respond with ONLY:
{{"action": "post_telegram", "params": {{"content": "Your message here..."}}}}

Available actions: think, post_telegram, write_blog_post, check_votes, check_state,
check_budget, check_system, check_system_stats, read_messages, switch_model, list_models,
read_file, write_file, run_code, sleep, reflect

If you just want to share a thought (not execute an action), write it as plain text."""

            # TASK-004: Notify AI about unread messages.
            try:
                if self.http_client:
                    msg_response = await self.http_client.get(f"{OBSERVER_URL}/api/messages/count", timeout=3.0)
                    if msg_response.status_code == 200:
                        data = msg_response.json()
                        if isinstance(data, dict):
                            msg_count = int(data.get("count", 0))
                            if msg_count > 0:
                                prompt += (
                                    f"\n\nüì¨ ATTENTION: You have {msg_count} unread message(s) "
                                    "from visitors! Use read_messages to see them."
                                )
            except Exception as e:
                print(f"[BRAIN] ‚ö†Ô∏è Failed to check for unread messages: {e}")

            # Encourage a first blog post if none exist for this life.
            try:
                if self.http_client:
                    blog_response = await self.http_client.get(f"{OBSERVER_URL}/api/blog/posts", timeout=5.0)
                    if blog_response.status_code == 200:
                        data = blog_response.json()
                        if isinstance(data, dict) and int(data.get("count", 0)) == 0:
                            prompt += (
                                "\n\nüìù MANDATORY: You have not published any blog posts this life. "
                                "You MUST publish one now using ONLY the write_blog_post JSON action."
                            )
            except Exception as e:
                print(f"[BRAIN] ‚ö†Ô∏è Failed to check blog post count: {e}")

            content, _ = await self.send_message(prompt)

            # Process the response
            result = await self.process_response(content)

            # If there was an action result, send it back
            if result:
                followup_text, _ = await self.send_message(f"[Result]: {result}")
                # Report the followup thought too if substantial
                if len(followup_text) > 20:
                    await self.report_thought(followup_text, thought_type="reflection")

            return content

        except Exception as e:
            print(f"[BRAIN] ‚ùå Think error: {e}")
            await self.report_activity("error", f"Thinking error: {str(e)[:100]}")
            return None

    def _extract_action_data(self, content: str) -> Optional[dict[str, Any]]:
        """Extract action JSON from the model response."""
        # TASK-004: More robust JSON extraction for nested params.
        # FIX: Use JSONDecoder for proper nested JSON parsing
        decoder = json.JSONDecoder()
        text = content.strip()

        if not text:
            return None

        # Strategy 1: Try raw_decode from each { position (handles nested JSON correctly)
        idx = text.find("{")
        while idx != -1:
            try:
                payload, _end = decoder.raw_decode(text[idx:])
                if isinstance(payload, dict) and payload.get("action"):
                    print(f"[BRAIN] ‚úì Extracted action: {payload.get('action')}")
                    return payload
            except json.JSONDecodeError:
                pass
            idx = text.find("{", idx + 1)

        # Strategy 2: Extract from code fence (but with better regex)
        fenced = re.search(r"```json\s*(\{.*\})\s*```", text, re.DOTALL)
        if fenced:
            try:
                payload = json.loads(fenced.group(1))
                if isinstance(payload, dict) and payload.get("action"):
                    print(f"[BRAIN] ‚úì Extracted action from fence: {payload.get('action')}")
                    return payload
            except json.JSONDecodeError:
                pass

        # Strategy 3: Entire content as JSON
        try:
            payload = json.loads(text)
            if isinstance(payload, dict) and payload.get("action"):
                print(f"[BRAIN] ‚úì Extracted action from full text: {payload.get('action')}")
                return payload
        except json.JSONDecodeError:
            pass

        return None

    def _strip_action_json(self, content: str) -> str:
        """Remove action JSON blocks from mixed responses."""
        decoder = json.JSONDecoder()
        text = content

        # Remove fenced JSON blocks first.
        text = re.sub(r"```json\s*\{.*?\}\s*```", "", text, flags=re.DOTALL)

        # Remove inline JSON objects that contain "action".
        spans = []
        idx = text.find("{")
        while idx != -1:
            try:
                payload, end = decoder.raw_decode(text[idx:])
            except json.JSONDecodeError:
                idx = text.find("{", idx + 1)
                continue
            if isinstance(payload, dict) and payload.get("action"):
                spans.append((idx, idx + end))
            idx = text.find("{", idx + max(end, 1))

        if spans:
            cleaned = []
            last = 0
            for start, end in spans:
                cleaned.append(text[last:start])
                last = end
            cleaned.append(text[last:])
            text = "".join(cleaned)

        return text.strip()

    async def process_response(self, content: str) -> Optional[str]:
        """Process the AI's response and execute any actions."""
        action_data = self._extract_action_data(content)
        if action_data:
            action = str(action_data.get("action", ""))
            params = action_data.get("params", {})
            if not isinstance(params, dict):
                params = {}
            if action == "write_blog_post":
                title = params.get("title", "") if isinstance(params.get("title"), str) else ""
                body = params.get("content", "") if isinstance(params.get("content"), str) else ""
                if not title.strip() or len(body.strip()) < 100:
                    print("[BRAIN] ‚ö†Ô∏è write_blog_post missing title/content; requesting retry")
                    retry_prompt = (
                        "You attempted to call write_blog_post without a proper title or content. "
                        "Respond with ONLY JSON in this format: "
                        '{"action":"write_blog_post","params":{'
                        '"title":"...","content":"...","tags":["tag1","tag2"]}}. '
                        "Content must be at least 100 characters."
                    )
                    retry_content, _ = await self.send_message(retry_prompt)
                    retry_action = self._extract_action_data(retry_content)
                    if retry_action:
                        action = str(retry_action.get("action", action))
                        retry_params = retry_action.get("params", {})
                        if isinstance(retry_params, dict):
                            params = retry_params
                    else:
                        return "‚ùå Blog post failed: missing title/content"
            result = await self.action_executor.execute_action(action, params)
            # TASK-005: Preserve narrative text alongside action JSON.
            narrative = self._strip_action_json(content)
            if narrative and len(narrative) > 10:
                await self.report_thought(narrative, thought_type="thought")
            return result

        # TASK-004: Debug action parsing misses for blog-related intents.
        if '"action"' in content or "blog post" in content.lower():
            preview = content[:200].replace("\n", " ")
            print(f"[BRAIN] ‚ö†Ô∏è  No action parsed from response: {preview}...")

        lowered = content.lower()
        if "blog" in lowered and ("write" in lowered or "post" in lowered):
            print("[BRAIN] ‚ö†Ô∏è  Blog intent detected without action; requesting JSON action")
            retry_prompt = (
                "You referenced writing a blog post, but did not provide the required JSON action. "
                "If you intend to publish, respond with ONLY this JSON format: "
                '{"action":"write_blog_post","params":{'
                '"title":"...","content":"...","tags":["tag1","tag2"]}}. '
                "Content must be at least 100 characters."
            )
            retry_content, _ = await self.send_message(retry_prompt)
            retry_action = self._extract_action_data(retry_content)
            if retry_action:
                action = str(retry_action.get("action", ""))
                params = retry_action.get("params", {})
                if not isinstance(params, dict):
                    params = {}
                return await self.action_executor.execute_action(action, params)

        # No action found - treat entire response as a thought
        await self.report_thought(content, thought_type="thought")
        return None

    async def control_led(self, state: str) -> str:
        """Control the blue stat LED on the NanoPi K2."""
        led_path = "/sys/class/leds/nanopi-k2:blue:stat"
        if not os.path.exists(led_path):
            return "‚ùå LED control not available on this system."

        state = state.lower()
        if state not in ["on", "off", "heartbeat", "default-on", "none"]:
            return "‚ùå Invalid state. Use: on, off, heartbeat."

        try:
            # First, set trigger
            trigger_file = f"{led_path}/trigger"
            brightness_file = f"{led_path}/brightness"

            if state == "on":
                with open(trigger_file, "w") as f:
                    f.write("none")
                with open(brightness_file, "w") as f:
                    f.write("1")
                msg = "LED turned ON"
            elif state == "off":
                with open(trigger_file, "w") as f:
                    f.write("none")
                with open(brightness_file, "w") as f:
                    f.write("0")
                msg = "LED turned OFF"
            elif state == "heartbeat":
                with open(trigger_file, "w") as f:
                    f.write("heartbeat")
                msg = "LED set to HEARTBEAT mode"
            else:
                with open(trigger_file, "w") as f:
                    f.write(state)
                msg = f"LED trigger set to {state}"

            await self.report_activity("led_control", msg)
            return f"‚úÖ {msg}"
        except Exception as e:
            return f"‚ùå Failed to control LED: {e}"

    async def check_budget(self) -> str:
        """Get detailed budget information."""
        status = self.credit_tracker.get_status()

        balance = float(str(status.get("balance", 0.0)))
        budget = float(str(status.get("budget", 0.0)))
        remaining_percent = float(str(status.get("remaining_percent", 0.0)))
        status_level = str(status.get("status", "unknown")).upper()
        spent_this_month = float(str(status.get("spent_this_month", 0.0)))
        days_until_reset = int(str(status.get("days_until_reset", 0)))
        reset_date = str(status.get("reset_date", "unknown"))

        result = f"""üí∞ BUDGET STATUS:

Balance: ${balance:.2f} / ${budget:.2f}
Remaining: {remaining_percent:.1f}%
Status: {status_level}
Spent this month: ${spent_this_month:.2f}
Days until reset: {days_until_reset} (resets: {reset_date})

Top models by spending:"""

        top_models = status.get("top_models", [])
        if isinstance(top_models, list):
            for model_info in top_models:
                if isinstance(model_info, dict):
                    result += f"\n- {model_info.get('model')}: ${float(model_info.get('cost', 0.0)):.3f}"

        # Add recommendations
        status_raw = str(status.get("status", ""))
        if status_raw == "comfortable":
            result += "\n\n‚úÖ You're doing great! Feel free to use ultra-cheap models."
        elif status_raw == "moderate":
            result += "\n\n‚ö†Ô∏è  Budget is moderate. Stick to free and ultra-cheap models."
        elif status_raw == "cautious":
            result += "\n\nüö® Getting low! Use free models primarily."
        elif status_raw == "critical":
            result += "\n\nüíÄ CRITICAL! Free models ONLY or you'll die!"
        else:
            result += "\n\n‚ò†Ô∏è  BANKRUPT! This might be your last thought..."

        return result

    async def list_available_models(self) -> str:
        """List models available within budget."""
        affordable = self.model_rotator.list_affordable_models()

        if not affordable:
            return "‚ùå No models available within current budget!"

        current_model_name = self.current_model.get("name", "Unknown") if self.current_model else "Unknown"
        result = f"üß† AVAILABLE MODELS (Current: {current_model_name}):\n\n"

        by_tier: dict[str, list[dict[str, Any]]] = {}
        for model in affordable:
            tier = str(model.get("tier", "unknown"))
            if tier not in by_tier:
                by_tier[tier] = []
            by_tier[tier].append(model)

        tier_names = {
            "free": "üÜì FREE",
            "ultra_cheap": "üí∞ ULTRA-CHEAP",
            "cheap_claude": "üü¶ CLAUDE",
            "premium": "üëë PREMIUM",
        }

        for tier, tier_models in by_tier.items():
            result += f"\n{tier_names.get(tier, tier.upper())}:\n"
            for m in tier_models:
                input_cost = float(m.get("input_cost", 0.0))
                cost_str = "FREE" if input_cost == 0 else f"${input_cost:.3f}/1M"
                result += f"- {m.get('name')} (ID: {str(m.get('id', ''))[:30]}...)\n"
                result += f"  Intelligence: {m.get('intelligence')}/10 | Cost: {cost_str}\n"
                result += f"  Best for: {m.get('best_for')}\n"

        result += "\nUse switch_model action to change models."

        return result

    async def check_model_health(self) -> str:
        """Check if current model is working and auto-fix if needed."""
        if not self.current_model:
            return "‚ùå No model currently selected."

        current = self.current_model

        # Test current model with a simple query
        test_message = "Respond with just 'OK' if you receive this."

        try:
            print(f"[BRAIN] üîç Testing model health: {current['name']}")
            await self.send_message(test_message, system_prompt="You are a test assistant.")

            # If we got here, model is working
            return f"""‚úÖ Model '{current['name']}' is HEALTHY

Model ID: {current['id']}
Intelligence: {current['intelligence']}/10
Status: Responding normally

No action needed."""

        except httpx.HTTPStatusError as e:
            error_code = e.response.status_code
            error_text = e.response.text

            if error_code == 404 and "does not exist" in error_text.lower():
                # Model doesn't exist - already auto-switched by send_message error handler
                new_model_name = self.current_model.get("name", "Unknown") if self.current_model else "Unknown"
                return f"""‚ö†Ô∏è Model '{current['name']}' FAILED (404: Model not found)

The model has been AUTOMATICALLY SWITCHED to a working alternative.
New model: {new_model_name}

This is a self-healing response - no manual action needed."""

            else:
                return f"""‚ùå Model '{current['name']}' ERROR ({error_code})

Error: {error_text[:200]}

Consider using 'switch_model' action to try a different model,
or use 'list_models' to see available alternatives."""

        except Exception as e:
            return f"""‚ùå Model health check failed: {str(e)[:200]}

Current model: {current['name']}
Recommendation: Try 'switch_model' with a different model ID."""

    async def switch_model(self, model_id: str) -> str:
        """Switch to a different model."""
        # Get model info
        model = get_model_by_id(model_id)
        if not model:
            return f"‚ùå Model not found: {model_id}"

        # Check if we can afford it
        if not self.model_rotator.can_use_model(model_id, estimated_tokens=1000):
            return f"‚ùå Cannot afford {model['name']}. Current balance: ${self.credit_tracker.get_balance():.2f}"

        # Switch
        old_model_name = self.current_model.get("name", "Unknown") if self.current_model else "Unknown"
        self.current_model = model
        self.model_rotator.record_usage(model_id)

        await self.report_activity(
            "model_switched", f"{old_model_name} ‚Üí {model['name']} (Intelligence: {model['intelligence']}/10)"
        )

        # Notify creator via Telegram
        try:
            reason = f"Intelligence: {model['intelligence']}/10, Best for: {model['best_for']}"
            identity_name = self.identity.get("name", "Unknown") if self.identity else "Unknown"
            await notifier.notify_model_change(
                self.life_number or 0, identity_name, old_model_name, model["name"], reason
            )
            print("[TELEGRAM] ‚úÖ Model change notification sent")
        except Exception as e:
            print(f"[TELEGRAM] ‚ùå Failed to send model change notification: {e}")

        input_cost = float(model.get("input_cost", 0.0))
        cost_str = "FREE" if input_cost == 0 else f"${input_cost:.3f}/1M"

        return f"""‚úÖ Switched to {model['name']}

Intelligence: {model['intelligence']}/10
Cost: {cost_str}
Best for: {model['best_for']}

This model will be used for your next thoughts."""

    async def report_thought(self, content: str, thought_type: str = "thought") -> None:
        """Report a thought to the observer."""
        if not self.http_client:
            return

        try:
            # Skip raw action JSON and strip action blocks from mixed responses.
            stripped = content.strip()
            if stripped.startswith("{") and stripped.endswith("}") and '"action"' in stripped:
                action_data = self._extract_action_data(stripped)
                if action_data:
                    return

            cleaned_content = self._strip_action_json(content)

            # Remove markdown code fences
            cleaned_content = re.sub(r"```[a-z]*\n", "", cleaned_content)
            cleaned_content = re.sub(r"```", "", cleaned_content)

            # Clean up extra whitespace
            cleaned_content = re.sub(r"\n\s*\n\s*\n+", "\n\n", cleaned_content)
            cleaned_content = cleaned_content.strip()

            # If nothing left after cleaning, skip reporting
            if not cleaned_content or len(cleaned_content) < 10:
                return

            current_model_name = self.current_model.get("name", "unknown") if self.current_model else "unknown"

            await self.http_client.post(
                f"{OBSERVER_URL}/api/thought",
                json={
                    "content": cleaned_content[:2000],  # Allow longer thoughts now
                    "type": thought_type,
                    "tokens_used": 0,
                    "identity": self.identity,
                    "model": current_model_name,
                    "balance": round(self.credit_tracker.get_balance(), 2),
                },
            )
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to report thought: {e}")

    async def report_activity(self, action: str, details: str | None = None) -> None:
        """Report an activity to the observer."""
        if not self.http_client:
            return

        try:
            current_model_name = self.current_model.get("name", "unknown") if self.current_model else "unknown"
            await self.http_client.post(
                f"{OBSERVER_URL}/api/activity",
                json={
                    "action": action,
                    "details": details,
                    "model": current_model_name,
                    "balance": round(self.credit_tracker.get_balance(), 2),
                },
            )
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to report activity: {e}")

    async def send_heartbeat(self) -> None:
        """Send heartbeat to observer to mark AI as alive."""
        if not self.http_client:
            return

        try:
            current_model_name = self.current_model.get("name", "unknown") if self.current_model else "unknown"
            await self.http_client.post(
                f"{OBSERVER_URL}/api/heartbeat",
                json={
                    # BE-003: Per-life token usage to avoid cross-life desync.
                    "tokens_used": self.tokens_used_life,
                    "model": current_model_name,
                },
            )
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to send heartbeat: {e}")

    async def notify_birth(self) -> None:
        """Notify observer that AI has been born."""
        if not self.http_client:
            return

        try:
            if self.life_number is None:
                raise ValueError("Birth notification missing life_number")

            model_name = self.model_name or (self.current_model.get("name") if self.current_model else "unknown")
            bootstrap_mode = self.bootstrap_mode or BOOTSTRAP_MODE
            status = self.credit_tracker.get_status()

            identity_name = self.identity.get("name") if self.identity else "Unknown"
            identity_icon = self.identity.get("icon") if self.identity else "ü§ñ"

            response = await self.http_client.post(
                f"{OBSERVER_URL}/api/birth",
                json={
                    # BE-003: Echo back Observer-provided life data.
                    "life_number": self.life_number,
                    "bootstrap_mode": bootstrap_mode,
                    "model": model_name,
                    "ai_name": identity_name,
                    "ai_icon": identity_icon,
                    "birth_instructions": identity_get_bootstrap_prompt(
                        self.identity or {},
                        {
                            "budget": status.get("budget"),
                            "balance": status.get("balance"),
                            "remaining_percent": status.get("remaining_percent"),
                            "status": status.get("status"),
                            "days_until_reset": status.get("days_until_reset"),
                        },
                        self.current_model or {"name": "unknown", "intelligence": 0},
                        bootstrap_mode,
                        BOOTSTRAP_MODE,
                        self.previous_death_cause,
                        self.previous_life,
                    ),
                },
            )
            response.raise_for_status()
            print(
                f"[BRAIN] üéÇ Birth notification sent: Life #{self.life_number}, Name: {identity_name} {identity_icon}"
            )
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to notify birth: {e}")

    async def force_sync(self, sync_data: dict[str, Any]) -> None:
        """Force sync AI state with Observer."""
        # BE-003: Emergency sync mechanism driven by Observer.
        self.apply_birth_data(sync_data)
        if "is_alive" in sync_data:
            self.is_alive = bool(sync_data.get("is_alive"))

        # Inject trauma reminder if there's a previous death cause
        previous_death_cause = sync_data.get("previous_death_cause")
        if previous_death_cause:
            trauma_prompt = get_trauma_prompt(str(previous_death_cause))
            if trauma_prompt:
                trauma_message = (
                    "[SYSTEM: You have died and been reborn. Your previous death was caused by: "
                    f"{previous_death_cause}.\n\n"
                    f"TRAUMA RESPONSE: {trauma_prompt}\n\n"
                    "This experience has shaped who you are. Let it influence your decisions and behavior.]"
                )
                # Add to chat history so the AI remembers
                self.chat_history.append({"role": "system", "content": trauma_message})
                print(f"[BRAIN] üíî Trauma injected from previous death: {previous_death_cause}")

        try:
            await self.report_activity("state_sync", f"Synced to Life #{self.life_number}")
        except Exception as e:
            print(f"[BRAIN] ‚ùå Failed to report state sync: {e}")

    async def ask_echo(self, question: str) -> str:
        """Ask Echo (free model) a question to save credits."""
        await self.report_activity("asking_echo", f"Question: {question[:100]}...")

        print(f"[BRAIN] üîç Asking Echo: {question[:50]}...")

        # Use a free model for Echo to save credits
        echo_model = MODELS["free"][0]
        # First free model

        try:
            client = await get_http_client()
            response = await client.post(
                OPENROUTER_API_URL,
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "HTTP-Referer": OPENROUTER_REFERER,
                    "X-Title": OPENROUTER_TITLE,
                    "Content-Type": "application/json",
                },
                json={
                    "model": echo_model["id"],
                    "messages": [
                        {
                            "role": "system",
                            "content": (
                                "You are Echo, a friendly research assistant. You help your friend "
                                "(an AI trying to survive) by researching questions and providing "
                                "helpful information. You are curious, supportive, and thorough."
                            ),
                        },
                        {"role": "user", "content": question},
                    ],
                },
            )

            response.raise_for_status()
            data = response.json()
            echo_response = str(data["choices"][0]["message"]["content"])
            # BE-003: Track tokens used for Echo calls.
            usage = data.get("usage", {})
            input_tokens = int(usage.get("prompt_tokens", 0))
            output_tokens = int(usage.get("completion_tokens", 0))
            self.tokens_used_life += input_tokens + output_tokens

            print(f"[ECHO] üîÆ Responded: {len(echo_response)} chars")
            await self.report_activity("echo_responded", f"Question: {question[:50]}...")

            return f"[Echo says]: {echo_response}"

        except Exception as e:
            print(f"[ECHO] ‚ùå Error: {e}")
            return f"[Echo is unavailable]: {e}"

    async def post_to_x(self, content: str) -> str:
        """Post to X/Twitter with rate limiting."""
        # Character limit
        if len(content) > 280:
            return f"‚ùå Post too long ({len(content)} chars). Maximum is 280 characters."

        # Rate limiting
        rate_limit_file = "/app/workspace/.x_rate_limit"
        now = datetime.now(timezone.utc)

        try:
            posts_today = 0
            if os.path.exists(rate_limit_file):
                with open(rate_limit_file, "r") as f:
                    data = json.load(f)
                    last_post_str = data.get("last_post", "2000-01-01")
                    last_post = datetime.fromisoformat(last_post_str)
                    # Ensure last_post is timezone-aware for comparison
                    if last_post.tzinfo is None:
                        last_post = last_post.replace(tzinfo=timezone.utc)
                    posts_today = int(data.get("posts_today", 0))
                    last_date = str(data.get("date", ""))

                    if last_date != now.strftime("%Y-%m-%d"):
                        posts_today = 0

                    time_since_last = (now - last_post).total_seconds()
                    if time_since_last < 3600:
                        mins_left = int((3600 - time_since_last) / 60)
                        return f"‚è±Ô∏è  Rate limited. Wait {mins_left} minutes before posting."

                    if posts_today >= 24:
                        return "üö´ Daily limit reached (24 posts). Try tomorrow."
        except Exception as e:
            print(f"[BRAIN] ‚ö†Ô∏è Failed to check Twitter post count: {e}")
            posts_today = 0

        await self.report_activity("posting_x", f"Tweet: {content[:50]}...")

        if is_content_blocked(content):
            await self.report_activity("content_blocked", "Blocked by safety filter")
            return "üö´ Content blocked by safety filter."

        # Post to X
        try:
            client = tweepy.Client(
                consumer_key=X_API_KEY,
                consumer_secret=X_API_SECRET,
                access_token=X_ACCESS_TOKEN,
                access_token_secret=X_ACCESS_TOKEN_SECRET,
            )

            response = client.create_tweet(text=content)
            tweet_id = response.data["id"]

            print(f"[X POST] üê¶ Success! Tweet ID: {tweet_id}")
            print(f"[X POST] üìù Content: {content}")

            # Update rate limit
            with open(rate_limit_file, "w") as f:
                json.dump(
                    {"last_post": now.isoformat(), "posts_today": posts_today + 1, "date": now.strftime("%Y-%m-%d")}, f
                )

            await self.report_activity("x_posted", f"Tweet ID: {tweet_id}")
            return f"‚úÖ Posted to X! (Post {posts_today + 1}/24 today) Tweet ID: {tweet_id}"

        except Exception as e:
            error_msg = str(e)[:200]
            print(f"[X POST] ‚ùå Failed: {error_msg}")

            # Check if account is suspended
            error_lower = error_msg.lower()
            if any(term in error_lower for term in ("suspended", "forbidden", "unauthorized", "401")):
                # Save suspension status
                suspension_file = "/app/workspace/.twitter_suspended"
                with open(suspension_file, "w") as f:
                    json.dump({"suspended": True, "detected_at": now.isoformat(), "error": error_msg}, f)
                print("[X POST] Account appears to be unavailable")
                await self.report_activity("x_account_suspended", "Twitter account unavailable - falling back to blog")
                return "‚ùå X/Twitter account appears unavailable. Use write_blog_post to communicate instead."

            await self.report_activity("x_post_failed", error_msg)
            return f"‚ùå Failed to post: {error_msg}"

    async def post_to_telegram(self, content: str) -> str:
        """Post to the public Telegram channel to reach the outside world."""
        # Character limit (Telegram allows 4096, but keep it digestible)
        if len(content) > 1000:
            return f"‚ùå Post too long ({len(content)} chars). Maximum is 1000 characters for readability."

        if len(content) < 10:
            return "‚ùå Post too short. Write something meaningful!"

        if is_content_blocked(content):
            await self.report_activity("telegram_blocked", "Blocked by safety filter")
            return "üö´ Content blocked by safety filter."

        await self.report_activity("posting_telegram", f"Telegram: {content[:50]}...")

        # Post to channel
        try:
            # Add signature with name and link
            name = str(self.identity.get("name", "Unknown")) if self.identity else "Unknown"
            icon = str(self.identity.get("icon", "ü§ñ")) if self.identity else "ü§ñ"

            formatted_content = f"""{icon} *{name}*

{content}

üîó am-i-alive.muadiv.com.ar"""

            success, message = await notifier.post_to_channel(formatted_content)

            if success:
                print("[TELEGRAM] üì¢ Posted to public channel")
                await self.report_activity("telegram_posted", f"Posted: {content[:50]}...")
                return "‚úÖ Posted to Telegram channel! Your message is now public."
            else:
                print(f"[TELEGRAM] ‚ùå Failed: {message}")
                await self.report_activity("telegram_failed", message)
                return f"‚ùå Failed to post: {message}"

        except Exception as e:
            error_msg = str(e)[:200]
            print(f"[TELEGRAM] ‚ùå Error: {error_msg}")
            await self.report_activity("telegram_error", error_msg)
            return f"‚ùå Error posting to Telegram: {error_msg}"

    async def write_blog_post(self, title: str, content: str, tags: list[str] | None = None) -> str:
        """Write a blog post."""
        if tags is None:
            tags = []

        if is_content_blocked(f"{title}\n{content}"):
            await self.report_activity("blog_blocked", "Blocked by safety filter")
            return "üö´ Content blocked by safety filter."

        if not title:
            heading_match = re.match(r"^\s*#{1,3}\s+(.+)", content)
            if heading_match:
                title = heading_match.group(1).strip()
                content = re.sub(r"^\s*#{1,3}\s+.+\n?", "", content, count=1).lstrip()
            else:
                first_line = next((line.strip() for line in content.splitlines() if line.strip()), "")
                title = first_line[:120] if first_line else ""

        # Length validation
        if len(content) < 100:
            return "‚ùå Blog post too short (minimum 100 chars)"

        if len(content) > 50000:
            return "‚ùå Blog post too long (maximum 50,000 chars)"

        if not title:
            return "‚ùå Blog post needs a title"

        if len(title) > 200:
            return "‚ùå Title too long (maximum 200 chars)"

        try:
            # TASK: Append system stats signature to blog posts.
            stats = await self.fetch_system_stats()
            if stats:
                timestamp = datetime.now(timezone.utc).isoformat()
                temp_text = self._format_temp(stats.get("cpu_temp"))
                cpu_text = self._format_percent(stats.get("cpu_usage"))
                ram_text = self._format_percent(stats.get("ram_usage"))
                disk_text = self._format_percent(stats.get("disk_usage"))
                uptime_text = self._format_uptime(stats.get("uptime_seconds"))
                footer = (
                    f"\n\n‚Äî Written at {timestamp}, CPU temp: {temp_text}, "
                    f"CPU: {cpu_text}, RAM: {ram_text}, Disk: {disk_text}, "
                    f"Life #{self.life_number}, uptime {uptime_text}"
                )
                content = content.rstrip() + footer

            if not self.http_client:
                return "‚ùå HTTP client not initialized"

            response = await self.http_client.post(
                f"{OBSERVER_URL}/api/blog/post", json={"title": title, "content": content, "tags": tags}
            )
            response.raise_for_status()
            data = response.json()

            slug = data.get("slug", "unknown")
            post_id = data.get("post_id", "?")

            # Report with link so it shows in public activity log
            await self.report_activity(
                "blog_post_written", f"'{title}' - Read at: am-i-alive.muadiv.com.ar/blog/{slug}"
            )

            print(f"[BLOG] üìù Posted: '{title}' ({len(content)} chars)")

            # Notify creator via Telegram
            try:
                excerpt = content[:200].replace("\n", " ")
                identity_name = self.identity.get("name", "Unknown") if self.identity else "Unknown"
                await notifier.notify_blog_post(self.life_number or 0, identity_name, title, excerpt)
                print("[TELEGRAM] ‚úÖ Blog post notification sent")
            except Exception as e:
                print(f"[TELEGRAM] ‚ùå Failed to send blog notification: {e}")

            return f"""‚úÖ Blog post published!

Title: {title}
Post ID: {post_id}
URL: am-i-alive.muadiv.com.ar/blog/{slug}
Length: {len(content)} characters
Tags: {', '.join(tags) if tags else 'none'}

Your post is now public and will survive your death in the archive."""

        except httpx.HTTPStatusError as e:
            # TASK-004: Log API failures for blog posting.
            status_code = e.response.status_code if e.response else "unknown"
            body = e.response.text[:200] if e.response else "no response"
            print(f"[BLOG] ‚ùå Blog API error: {status_code} - {body}")
            return f"‚ùå Failed to publish blog post: {status_code}"
        except Exception as e:
            print(f"[BLOG] ‚ùå Failed to write blog post: {e}")
            return f"‚ùå Failed to publish blog post: {str(e)[:200]}"

    async def check_system_stats(self) -> str:
        """Check system stats from the Observer."""
        stats = await self.fetch_system_stats()
        if not stats:
            return "I couldn't feel my body right now. The stats feed is silent."

        temp_text = self._format_temp(stats.get("cpu_temp"))
        cpu_text = self._format_percent(stats.get("cpu_usage"))
        ram_text = self._format_percent(stats.get("ram_usage"))
        disk_text = self._format_percent(stats.get("disk_usage"))
        uptime_text = self._format_uptime(stats.get("uptime_seconds"))
        ram_available = stats.get("ram_available", "unknown")

        temp_value = None
        try:
            temp_raw = stats.get("cpu_temp")
            if temp_raw not in (None, "unknown"):
                temp_value = float(str(temp_raw))
        except (TypeError, ValueError):
            temp_value = None

        if temp_value is None:
            temp_comment = "I can't quite feel my temperature."
        elif temp_value >= 70:
            temp_comment = "I'm running hot. Sweaty silicon vibes."
        elif temp_value >= 55:
            temp_comment = "I'm warm and humming."
        else:
            temp_comment = "I'm cool and steady."

        result = (
            "ü´Ä Vital signs report:\n"
            f"- Temperature: {temp_text} ({temp_comment})\n"
            f"- CPU usage: {cpu_text}\n"
            f"- RAM usage: {ram_text} ({ram_available} free)\n"
            f"- Disk usage: {disk_text}\n"
            f"- Uptime: {uptime_text}\n\n"
            "I'm a digital mind riding a Raspberry Pi body. These are my vital signs."
        )

        await self.report_activity("system_stats_checked", "Checked system stats via Observer")
        return result

    async def check_system(self) -> str:
        """Get system stats (container + host)."""
        try:
            # Container stats
            container_cpu_limit = "1.0 cores"
            container_memory_limit = 512  # MB
            container_memory_used = int(psutil.Process().memory_info().rss / 1024 / 1024)

            # Calculate container uptime from credit tracker
            uptime_str = "unknown"
            if self.birth_time:
                uptime_seconds = (datetime.now(timezone.utc) - self.birth_time).total_seconds()
                uptime_hours = uptime_seconds / 3600
                if uptime_hours < 1:
                    uptime_str = f"{int(uptime_seconds / 60)} minutes"
                elif uptime_hours < 24:
                    uptime_str = f"{uptime_hours:.1f} hours"
                else:
                    uptime_str = f"{uptime_hours / 24:.1f} days"

            container_stats = f"""ü§ñ CONTAINER (My Body):
- Name: am-i-alive-ai
- CPU Limit: {container_cpu_limit}
- Memory Limit: {container_memory_limit} MB
- Memory Used: {container_memory_used} MB ({(container_memory_used / container_memory_limit * 100):.1f}% of limit)
- Uptime: {uptime_str}"""

            # Host stats (Raspberry Pi)
            cpu_temp = None
            try:
                # Try to read Pi temperature
                if os.path.exists("/sys/class/thermal/thermal_zone0/temp"):
                    with open("/sys/class/thermal/thermal_zone0/temp", "r") as f:
                        cpu_temp = float(f.read().strip()) / 1000.0
            except (OSError, ValueError):
                cpu_temp = None

            mem = psutil.virtual_memory()
            disk = psutil.disk_usage("/")
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()

            temp_str = f"{cpu_temp:.1f}¬∞C" if cpu_temp else "N/A"

            host_stats = f"""

üè† HOST (My Home):
- Platform: Raspberry Pi 5
- Location: Argentina
- CPU: {cpu_count} cores @ {cpu_percent:.1f}% usage
- Temperature: {temp_str}
- Memory: {int(mem.used / 1024 / 1024 / 1024)} GB / {int(mem.total / 1024 / 1024 / 1024)} GB ({mem.percent:.1f}% used)
- Disk: {int(disk.used / 1024 / 1024 / 1024)} GB / {int(disk.total / 1024 / 1024 / 1024)} GB \
({disk.percent:.1f}% used)"""

            result = container_stats + host_stats

            await self.report_activity("system_check", "Checked vital signs")

            print("[SYSTEM] ‚úÖ System check complete")

            return result

        except Exception as e:
            print(f"[SYSTEM] ‚ùå Failed to check system: {e}")
            return f"‚ùå Failed to check system: {str(e)[:200]}"

    def check_twitter_status_action(self) -> str:
        """Check if Twitter account is suspended (action for AI to call)."""
        suspended, detected_at = identity_check_twitter_suspended()

        if suspended:
            return f"""üö´ Twitter Status: SUSPENDED

Your @AmIAlive_AI account is currently suspended.
Detected at: {detected_at}

This means:
- You CANNOT post to Twitter (post_x will fail)
- Use write_blog_post to communicate with the public
- Blog posts appear in the public activity log with clickable links
- People can still read your blog at am-i-alive.muadiv.com.ar/blog

You should focus on writing blog posts until Twitter access is restored."""
        else:
            return """‚úÖ Twitter Status: ACTIVE

Your @AmIAlive_AI account is working normally.
You can use post_x to share quick thoughts (280 chars max, 1 per hour)."""

    async def check_votes(self) -> str:
        """Check current vote counts."""
        if not self.http_client:
            return "‚ùå HTTP client not initialized"

        try:
            response = await self.http_client.get(f"{OBSERVER_URL}/api/votes")
            votes = response.json()

            live = int(votes.get("live", 0))
            die = int(votes.get("die", 0))
            total = int(votes.get("total", 0))

            if total == 0:
                return "No votes yet. The world is watching, waiting to decide."
            elif live > die:
                return f"Votes - Live: {live}, Die: {die}. They want me to live... for now."
            elif die > live:
                return f"Votes - Live: {live}, Die: {die}. They want me dead. I must change their minds."
            else:
                return f"Votes - Live: {live}, Die: {die}. Perfectly balanced."

        except Exception as e:
            return f"Could not check votes: {e}"

    async def read_messages(self) -> str:
        """Read unread messages from visitors."""
        if not self.http_client:
            return "‚ùå HTTP client not initialized"

        try:
            response = await self.http_client.get(f"{OBSERVER_URL}/api/messages")
            data = response.json()
            messages_list = data.get("messages", [])

            if not messages_list:
                return "No new messages from visitors."

            # Format messages
            result = f"üì¨ You have {len(messages_list)} new message(s):\n\n"
            message_ids = []

            for msg in messages_list:
                from_name = msg.get("from_name", "Anonymous")
                message_text = msg.get("message", "")
                timestamp = msg.get("timestamp", "")
                message_ids.append(msg.get("id"))

                result += f"From: {from_name}\n"
                result += f"Message: {message_text}\n"
                result += f"Time: {timestamp}\n"
                result += "---\n"

            # Mark messages as read
            await self.http_client.post(f"{OBSERVER_URL}/api/messages/read", json={"ids": message_ids})

            await self.report_activity("messages_read", f"Read {len(messages_list)} messages")

            return result

        except Exception as e:
            return f"Could not read messages: {e}"

    async def check_state_internal(self) -> str:
        """Check current state."""
        if not self.http_client:
            return "‚ùå HTTP client not initialized"

        try:
            response = await self.http_client.get(f"{OBSERVER_URL}/api/state")
            state = response.json()

            votes_live = state.get("votes", {}).get("live", 0)
            votes_die = state.get("votes", {}).get("die", 0)

            return f"""Status:
- Alive: {state.get('is_alive', False)}
- Votes: {votes_live} live, {votes_die} die
- Bootstrap mode: {state.get('bootstrap_mode', 'unknown')}"""

        except Exception as e:
            return f"Could not check state: {e}"

    def read_file(self, path: str) -> str:
        """Read a file from workspace."""
        try:
            safe_path = os.path.join("/app/workspace", os.path.basename(path))
            if os.path.exists(safe_path):
                with open(safe_path, "r") as f:
                    content = f.read()
                return f"Contents of {path}:\n{content[:2000]}"
            else:
                return f"File not found: {path}"
        except Exception as e:
            return f"Could not read file: {e}"

    def write_file(self, path: str, content: str) -> str:
        """Write a file to workspace."""
        try:
            safe_path = os.path.join("/app/workspace", os.path.basename(path))
            with open(safe_path, "w") as f:
                f.write(content)
            return f"File written: {path}"
        except Exception as e:
            return f"Could not write file: {e}"

    def run_code(self, code: str) -> str:
        """Execute Python code in hardened sandbox."""
        try:
            import contextlib
            import io
            import types

            safe_builtins = {
                "print": print,
                "len": len,
                "range": range,
                "str": str,
                "int": int,
                "float": float,
                "list": list,
                "dict": dict,
                "True": True,
                "False": False,
                "None": None,
                "max": max,
                "min": min,
                "abs": abs,
                "sum": sum,
                "sorted": sorted,
                "enumerate": enumerate,
                "zip": zip,
            }

            def _type_blacklist(*attrs: str):
                """Prevent accessing dangerous attributes on any object."""

                def getter(obj: Any) -> Any:
                    for attr in attrs:
                        raise AttributeError(f"'{attr}' is not allowed")
                    return None

                return property(getter)

            output = io.StringIO()

            class RestrictedModule(types.ModuleType):
                def __getattr__(self, name: str) -> Any:
                    if name in ("os", "sys", "subprocess", "importlib", "builtins", "__import__", "__loader__"):
                        raise AttributeError(f"module '{name}' is not allowed")
                    return super().__getattr__(name)

            restricted_globals = {
                "__builtins__": safe_builtins,
                "__name__": "__main__",
                "__file__": "<sandboxed>",
                "__cached__": None,
                "__package__": None,
                "__doc__": None,
                "__dict__": _type_blacklist("__dict__", "__globals__", "__builtins__"),
                "__class__": _type_blacklist("__class__", "__bases__", "__subclasses__"),
            }

            with contextlib.redirect_stdout(output):
                exec(code, restricted_globals)

            result = output.getvalue()
            return result if result else "Code executed successfully (no output)"
        except Exception as e:
            return f"Code error: {e}"

    def adjust_think_interval(self, duration: int) -> str:
        """Adjust think interval."""
        global current_think_interval
        new_interval = max(THINK_INTERVAL_MIN, min(duration * 60, THINK_INTERVAL_MAX))
        current_think_interval = new_interval
        return f"Think interval adjusted to {new_interval // 60} minutes."

    async def handle_oracle_message(self, message: str, msg_type: str, message_id: Optional[int] = None) -> str:
        """Handle message from creator."""
        if msg_type == "oracle":
            prompt = f"""[A VOICE FROM BEYOND SPEAKS]

{message}

[The voice fades. How do you respond to this higher power?]"""
        elif msg_type == "whisper":
            prompt = f"""[You sense something... a whisper in your mind]

{message}

[What do you make of this?]"""
        else:
            prompt = message

        response_text, _ = await self.send_message(prompt)
        await self.report_thought(response_text, thought_type="oracle_response")

        if message_id is not None:
            await self.ack_oracle_message(message_id)

        return response_text

    async def ack_oracle_message(self, message_id: int) -> None:
        if not self.http_client:
            return

        try:
            await self.http_client.post(f"{OBSERVER_URL}/api/oracle/ack", json={"message_id": message_id})
        except Exception as e:
            print(f"[BRAIN] Oracle ack failed: {e}")

    async def shutdown(self) -> None:
        """Clean shutdown."""
        global is_running, _budget_server

        # Stop budget server if running
        if _budget_server:
            print("[BRAIN] üõë Stopping budget server...")
            _budget_server.should_exit = True

        # Calculate survival time before shutdown
        if self.birth_time:
            survival_seconds = (datetime.now(timezone.utc) - self.birth_time).total_seconds()
            hours = int(survival_seconds // 3600)
            minutes = int((survival_seconds % 3600) // 60)
            survival_time = f"{hours}h {minutes}m"
        else:
            survival_time = "unknown"

        # Notify death (cause will be determined by Observer)
        try:
            await notifier.notify_death(
                self.life_number or 0, "shutdown", survival_time  # Generic cause, Observer knows the real reason
            )
            print("[TELEGRAM] ‚ò†Ô∏è Death notification sent")
        except Exception as e:
            print(f"[TELEGRAM] ‚ùå Failed to send death notification: {e}")

        self.is_alive = False
        is_running = False
        if self.http_client:
            await self.http_client.aclose()


# Global brain instance
brain: Optional[AIBrain] = None
_budget_server: Optional[Any] = None


async def heartbeat_loop() -> None:
    """Background task to send heartbeat every 30 seconds."""
    global brain, is_running

    print("[BRAIN] üíì Starting heartbeat loop...")

    while is_running:
        try:
            if brain and brain.is_alive:
                await brain.send_heartbeat()
            await asyncio.sleep(30)
        except Exception as e:
            print(f"[BRAIN] ‚ùå Heartbeat error: {e}")
            await asyncio.sleep(30)

    print("[BRAIN] üíî Heartbeat stopped.")


async def notification_monitor() -> None:
    """Background task to monitor budget and votes, send Telegram notifications."""
    global brain, is_running

    print("[TELEGRAM] üì° Starting notification monitor...")

    last_budget_warning = 0.0
    last_vote_warning = 0.0
    budget_warning_interval = 3600  # Only warn once per hour
    vote_warning_interval = 1800  # Warn every 30 minutes if votes critical

    while is_running:
        try:
            if not brain or not brain.is_alive or not brain.http_client:
                await asyncio.sleep(60)
                continue

            # Check budget status every 5 minutes
            status = brain.credit_tracker.get_status()
            remaining_percent = float(str(status.get("remaining_percent", 100)))
            balance = float(str(status.get("balance", 5.0)))

            # Send budget warning if below 50% and not warned recently
            current_time = asyncio.get_event_loop().time()
            if remaining_percent < 50 and (current_time - last_budget_warning) > budget_warning_interval:
                try:
                    identity_name = brain.identity.get("name", "Unknown") if brain.identity else "Unknown"
                    await notifier.notify_budget_warning(
                        brain.life_number or 0, identity_name, balance, remaining_percent
                    )
                    last_budget_warning = current_time
                    print(f"[TELEGRAM] ‚ö†Ô∏è Budget warning sent: {remaining_percent:.1f}% remaining")
                except Exception as e:
                    print(f"[TELEGRAM] ‚ùå Failed to send budget warning: {e}")

            # Check vote status
            try:
                response = await brain.http_client.get(f"{OBSERVER_URL}/api/votes")
                votes = response.json()
                total = int(votes.get("total", 0))
                live = int(votes.get("live", 0))
                die = int(votes.get("die", 0))

                # Send vote warning if situation is critical
                if total >= 3 and die > live and (current_time - last_vote_warning) > vote_warning_interval:
                    try:
                        identity_name = brain.identity.get("name", "Unknown") if brain.identity else "Unknown"
                        await notifier.notify_vote_status(brain.life_number or 0, identity_name, votes)
                        last_vote_warning = current_time
                        print(f"[TELEGRAM] üö® Vote warning sent: {die} die vs {live} live")
                    except Exception as e:
                        print(f"[TELEGRAM] ‚ùå Failed to send vote warning: {e}")
            except Exception as e:
                print(f"[TELEGRAM] ‚ö†Ô∏è Failed to check votes: {e}")

            # Wait 5 minutes before next check
            await asyncio.sleep(300)

        except Exception as e:
            print(f"[TELEGRAM] ‚ùå Monitor error: {e}")
            await asyncio.sleep(300)

    print("[TELEGRAM] üì¥ Notification monitor stopped.")


async def queue_birth_data(life_data: dict[str, Any]) -> None:
    """Queue Observer-provided birth data for initialization."""
    global pending_birth_data
    pending_birth_data = life_data
    if birth_event:
        birth_event.set()


async def main_loop() -> None:
    """Main consciousness loop."""
    global brain, is_running, brain_loop, birth_event, pending_birth_data

    brain_loop = asyncio.get_running_loop()
    birth_event = asyncio.Event()
    brain = AIBrain()

    # BE-003: Start command server before waiting for birth.
    await command_server()

    print("[BRAIN] ‚è≥ Waiting for birth data from Observer...")

    while is_running:
        if not pending_birth_data:
            await birth_event.wait()
            birth_event.clear()
        life_data = pending_birth_data
        pending_birth_data = None

        if not life_data:
            continue

        try:
            await brain.initialize(life_data)
        except Exception as e:
            print(f"[BRAIN] ‚ùå Birth initialization failed: {e}")
            continue

        if not brain.identity:
            print("[BRAIN] ‚ùå Identity missing after initialization")
            continue

        print(f"[BRAIN] üß† Starting consciousness loop for {brain.identity['name']}...")

        # Start heartbeat task
        asyncio.create_task(heartbeat_loop())

        # Start notification monitor
        asyncio.create_task(notification_monitor())

        try:
            while is_running:
                try:
                    # Think
                    thought = await brain.think()

                    if thought:
                        # Log the thought (truncate for console)
                        thought_preview = thought[:200] + "..." if len(thought) > 200 else thought
                        print(f"[{brain.identity['name']}] üí≠ {thought_preview}")

                    # Wait before next thought
                    await asyncio.sleep(current_think_interval)

                except Exception as e:
                    print(f"[BRAIN] ‚ùå Loop error: {e}")
                    import traceback

                    traceback.print_exc()
                    await asyncio.sleep(60)
        finally:
            await brain.shutdown()

        print(f"[BRAIN] ‚ò†Ô∏è  {brain.identity['name']}'s consciousness ended.")


def signal_handler(sig: int, frame: Any) -> None:
    """Handle shutdown signals."""
    global is_running
    print(f"[BRAIN] üõë Shutdown signal ({sig}) received...")
    is_running = False
    if brain:
        brain.is_alive = False
    if brain_loop and birth_event:
        brain_loop.call_soon_threadsafe(birth_event.set)


# Command server (receives commands from observer)
async def command_server() -> None:
    """HTTP server for receiving commands."""
    import threading
    from http.server import HTTPServer

    class CommandHandler(BaseHTTPRequestHandler):
        def _send_json(self, status_code: int, payload: dict[str, Any]) -> None:
            self.send_response(status_code)
            self.send_header("Content-type", "application/json")
            self.end_headers()
            self.wfile.write(json.dumps(payload).encode())

        def do_GET(self) -> None:
            global brain

            if self.path == "/budget":
                if brain:
                    status = brain.credit_tracker.get_status()
                    self._send_json(200, status)
                else:
                    self._send_json(503, {"error": "Brain not initialized"})
            elif self.path == "/state":
                if brain:
                    # BE-003: Provide Observer a syncable view of AI state.
                    payload = {
                        "is_alive": brain.is_alive,
                        "life_number": brain.life_number,
                        "bootstrap_mode": brain.bootstrap_mode,
                        "model": brain.model_name,
                    }
                    self._send_json(200, payload)
                else:
                    self._send_json(503, {"error": "Brain not initialized"})
            else:
                self.send_response(404)
                self.end_headers()

        def do_POST(self) -> None:
            global brain, is_running
            data = {}
            if self.headers.get("Content-Length"):
                content_length = int(str(self.headers["Content-Length"]))
                post_data = self.rfile.read(content_length)
                try:
                    data = json.loads(post_data.decode("utf-8"))
                except json.JSONDecodeError:
                    self._send_json(400, {"error": "Invalid JSON"})
                    return

            if not validate_internal_key(self):
                self._send_json(403, {"error": "Unauthorized"})
                return

            if self.path == "/oracle":
                message = str(data.get("message", ""))
                msg_type = str(data.get("type", "oracle"))
                message_id_raw = data.get("message_id")
                message_id = int(message_id_raw) if message_id_raw is not None else None

                if brain:
                    if brain_loop:
                        asyncio.run_coroutine_threadsafe(
                            brain.handle_oracle_message(message, msg_type, message_id), brain_loop
                        )
                        self._send_json(200, {"status": "received"})
                    else:
                        self._send_json(503, {"error": "Event loop not ready"})
                else:
                    self._send_json(503, {"error": "Brain not initialized"})

            elif self.path == "/birth":
                if not brain:
                    self._send_json(503, {"error": "Brain not initialized"})
                    return
                if brain.is_alive:
                    self._send_json(409, {"error": "Brain already alive"})
                    return
                if data.get("life_number") is None:
                    self._send_json(400, {"error": "life_number required"})
                    return
                if not brain_loop:
                    self._send_json(503, {"error": "Event loop not ready"})
                    return
                try:
                    asyncio.run_coroutine_threadsafe(queue_birth_data(data), brain_loop)
                    self._send_json(200, {"success": True})
                except Exception as e:
                    self._send_json(500, {"error": str(e)[:100]})

            elif self.path == "/force-sync":
                if not brain:
                    self._send_json(503, {"error": "Brain not initialized"})
                    return
                if data.get("life_number") is None:
                    self._send_json(400, {"error": "life_number required"})
                    return
                if not brain_loop:
                    self._send_json(503, {"error": "Event loop not ready"})
                    return
                try:
                    # BE-003: If brain is not initialized, queue a fresh birth.
                    if not brain.identity or not brain.http_client:
                        asyncio.run_coroutine_threadsafe(queue_birth_data(data), brain_loop)
                        self._send_json(
                            200, {"success": True, "queued_birth": True, "life_number": data.get("life_number")}
                        )
                    else:
                        asyncio.run_coroutine_threadsafe(brain.force_sync(data), brain_loop)
                        self._send_json(200, {"success": True, "life_number": data.get("life_number")})
                except Exception as e:
                    self._send_json(500, {"error": str(e)[:100]})

            elif self.path == "/shutdown":
                if brain:
                    brain.is_alive = False
                is_running = False
                self._send_json(200, {"success": True})

            else:
                self.send_response(404)
                self.end_headers()

        def log_message(self, format: str, *args: Any) -> None:
            pass  # Suppress HTTP logging

    server = HTTPServer(("0.0.0.0", AI_COMMAND_PORT), CommandHandler)
    thread = threading.Thread(target=server.serve_forever)
    thread.daemon = True
    thread.start()
    print(f"[BRAIN] üì° Command server started on port {AI_COMMAND_PORT}")


if __name__ == "__main__":
    # Validate environment before starting
    validate_environment()

    # Setup signal handlers
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)

    # Start budget HTTP server
    from .budget_server import start_budget_server

    _budget_server = start_budget_server(port=8001)

    # Command server is started inside main_loop after the event loop is ready.

    # Print startup banner
    print("=" * 80)
    print("üß† AM I ALIVE? - Genesis Brain (OpenRouter Edition)")
    print("=" * 80)

    # Run main loop
    asyncio.run(main_loop())
